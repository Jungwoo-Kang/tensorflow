{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Module: tf.keras.initializers](https://www.tensorflow.org/api_docs/python/tf/keras/initializers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.]\n",
      " [-2.]\n",
      " [-3.]\n",
      " [-4.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "x_data = np.array([[1.],[2.],[3.],[4.]]).astype(np.float32) # (4,1)\n",
    "y_data = np.array([1.,2.,3.,4.]).astype(np.float32) # (4,)\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=(None,1)) # (4,1)\n",
    "y = tf.placeholder(tf.float32, shape=(None,)) # (4,)\n",
    "\n",
    "if 0:\n",
    "    # Initializer that generates tensors with constant values.\n",
    "    alpha = tf.get_variable('alpha', (), dtype=tf.float32, initializer=tf.keras.initializers.constant(0.0))\n",
    "    beta = tf.get_variable('beta', (1,1), dtype=tf.float32, initializer=tf.keras.initializers.constant(1.0))\n",
    "elif 0:\n",
    "    # Initializer that generates tensors with a uniform distribution.\n",
    "    # https://www.tensorflow.org/api_docs/python/tf/random_uniform_initializer\n",
    "    alpha = tf.get_variable('alpha', (), dtype=tf.float32, initializer=tf.keras.initializers.constant(0.0))\n",
    "    beta = tf.get_variable('beta', (1,1), dtype=tf.float32, initializer=tf.keras.initializers.RandomUniform())\n",
    "elif 0:\n",
    "    # Initializer that generates tensors with a normal distribution.\n",
    "    # https://www.tensorflow.org/api_docs/python/tf/random_normal_initializer\n",
    "    alpha = tf.get_variable('alpha', (), dtype=tf.float32, initializer=tf.keras.initializers.constant(0.0))\n",
    "    beta = tf.get_variable('beta', (1,1), dtype=tf.float32, initializer=tf.keras.initializers.RandomNormal())\n",
    "elif 0:\n",
    "    # Initializer that generates a truncated normal distribution.\n",
    "    # https://www.tensorflow.org/api_docs/python/tf/keras/initializers/TruncatedNormal  \n",
    "    # These values are similar to values from a random_normal_initializer \n",
    "    # except that values more than two standard deviations from the mean are discarded and re-drawn. \n",
    "    # This is the recommended initializer for neural network weights and filters.\n",
    "    alpha = tf.get_variable('alpha', (), dtype=tf.float32, initializer=tf.keras.initializers.constant(0.0))\n",
    "    beta = tf.get_variable('beta', (1,1), dtype=tf.float32, initializer=tf.keras.initializers.truncated_normal())\n",
    "elif 0:\n",
    "    # The Glorot uniform initializer, also called Xavier uniform initializer.\n",
    "    # https://www.tensorflow.org/api_docs/python/tf/keras/initializers/GlorotUniform\n",
    "    # It draws samples from a uniform distribution within [-limit, limit] with\n",
    "    # limit = sqrt(6 / (fan_in + fan_out)) \n",
    "    # where fan_in is the number of input units in the weight tensor and \n",
    "    # fan_out is the number of output units in the weight tensor.\n",
    "    alpha = tf.get_variable('alpha', (), dtype=tf.float32, initializer=tf.keras.initializers.constant(0.0))\n",
    "    beta = tf.get_variable('beta', (1,1), dtype=tf.float32, initializer=tf.keras.initializers.glorot_uniform())\n",
    "elif 0:\n",
    "    # The Glorot normal initializer, also called Xavier normal initializer.\n",
    "    # https://www.tensorflow.org/api_docs/python/tf/keras/initializers/GlorotNormal\n",
    "    # It draws samples from a truncated normal distribution centered on 0 with \n",
    "    # stddev = sqrt(2 / (fan_in + fan_out)) \n",
    "    # where fan_in is the number of input units in the weight tensor and \n",
    "    # fan_out is the number of output units in the weight tensor.\n",
    "    alpha = tf.get_variable('alpha', (), dtype=tf.float32, initializer=tf.keras.initializers.constant(0.0))\n",
    "    beta = tf.get_variable('beta', (1,1), dtype=tf.float32, initializer=tf.keras.initializers.glorot_normal())\n",
    "elif 0:\n",
    "    # He uniform initializer.\n",
    "    # https://www.tensorflow.org/api_docs/python/tf/keras/initializers/he_uniform\n",
    "    # It draws samples from a uniform distribution within [-limit, limit] with\n",
    "    # limit = sqrt(6 / fan_in) \n",
    "    # where fan_in is the number of input units in the weight tensor.\n",
    "    alpha = tf.get_variable('alpha', (), dtype=tf.float32, initializer=tf.keras.initializers.constant(0.0))\n",
    "    beta = tf.get_variable('beta', (1,1), dtype=tf.float32, initializer=tf.keras.initializers.he_uniform())\n",
    "elif 0:\n",
    "    # He normal initializer.\n",
    "    # https://www.tensorflow.org/api_docs/python/tf/keras/initializers/he_normal\n",
    "    # It draws samples from a truncated normal distribution centered on 0 with \n",
    "    # stddev = sqrt(2 / fan_in) \n",
    "    # where fan_in is the number of input units in the weight tensor.\n",
    "    alpha = tf.get_variable('alpha', (), dtype=tf.float32, initializer=tf.keras.initializers.constant(0.0))\n",
    "    beta = tf.get_variable('beta', (1,1), dtype=tf.float32, initializer=tf.keras.initializers.he_normal())\n",
    "elif 0:\n",
    "    # LeCun uniform initializer.\n",
    "    # https://www.tensorflow.org/api_docs/python/tf/keras/initializers/lecun_uniform\n",
    "    # It draws samples from a uniform distribution within [-limit, limit] with\n",
    "    # limit = sqrt(3 / fan_in) \n",
    "    # where fan_in is the number of input units in the weight tensor.\n",
    "    alpha = tf.get_variable('alpha', (), dtype=tf.float32, initializer=tf.keras.initializers.constant(0.0))\n",
    "    beta = tf.get_variable('beta', (1,1), dtype=tf.float32, initializer=tf.keras.initializers.lecun_uniform())\n",
    "elif 0:\n",
    "    # LeCun normal initializer.\n",
    "    # https://www.tensorflow.org/api_docs/python/tf/keras/initializers/lecun_normal\n",
    "    # It draws samples from a truncated normal distribution centered on 0 with \n",
    "    # stddev = sqrt(1 / fan_in) \n",
    "    # where fan_in is the number of input units in the weight tensor.\n",
    "    alpha = tf.get_variable('alpha', (), dtype=tf.float32, initializer=tf.keras.initializers.constant(0.0))\n",
    "    beta = tf.get_variable('beta', (1,1), dtype=tf.float32, initializer=tf.keras.initializers.lecun_normal())\n",
    "elif 0:\n",
    "    # Initializer capable of adapting its scale to the shape of weights tensors.\n",
    "    # http://localhost:8888/notebooks/Dropbox/Git/tensorflow/tf_get_variable/tf.get_variable.ipynb\n",
    "    #\n",
    "    # With distribution=\"truncated_normal\" or \"untruncated_normal\", \n",
    "    # samples are drawn from a truncated/untruncated normal distribution \n",
    "    # with a mean of zero and a standard deviation (after truncation, if used) \n",
    "    # stddev = sqrt(scale / n) \n",
    "    # where n is: \n",
    "    # - number of input units in the weight tensor, if mode = \"fan_in\" \n",
    "    # - number of output units, if mode = \"fan_out\" \n",
    "    # - average of the numbers of input and output units, if mode = \"fan_avg\"\n",
    "    #\n",
    "    # With distribution=\"uniform\", \n",
    "    # samples are drawn from a uniform distribution within [-limit, limit], with \n",
    "    # limit = sqrt(3 * scale / n).\n",
    "    alpha = tf.get_variable('alpha', (), dtype=tf.float32, initializer=tf.keras.initializers.constant(0.0))\n",
    "    beta = tf.get_variable('beta', (1,1), dtype=tf.float32, initializer=tf.keras.initializers.VarianceScaling())\n",
    "elif 0:\n",
    "    # Initializer that generates the identity matrix.\n",
    "    # https://www.tensorflow.org/api_docs/python/tf/keras/initializers/Identity\n",
    "    # (ValueError: Identity matrix initializer can only be used for 2D matrices.)\n",
    "    alpha = tf.get_variable('alpha', (), dtype=tf.float32, initializer=tf.keras.initializers.constant(0.0))\n",
    "    beta = tf.get_variable('beta', (1,1), dtype=tf.float32, initializer=tf.keras.initializers.identity())\n",
    "elif 1:\n",
    "    # Initializer capable of adapting its scale to the shape of weights tensors.\n",
    "    # https://www.tensorflow.org/api_docs/python/tf/keras/initializers/Orthogonal\n",
    "    # (ValueError: The tensor to initialize must be at least two-dimensional)\n",
    "    #\n",
    "    # If the shape of the tensor to initialize is two-dimensional, \n",
    "    # it is initialized with an orthogonal matrix obtained \n",
    "    # from the QR decomposition of a matrix of random numbers drawn from a normal distribution. \n",
    "    # If the matrix has fewer rows than columns then the output will have orthogonal rows. \n",
    "    # Otherwise, the output will have orthogonal columns.\n",
    "    #\n",
    "    # If the shape of the tensor to initialize is more than two-dimensional, \n",
    "    # a matrix of shape (shape[0] * ... * shape[n - 2], shape[n - 1]) is initialized, \n",
    "    # where n is the length of the shape vector. The matrix is subsequently reshaped to give a tensor of the desired shape.\n",
    "    alpha = tf.get_variable('alpha', (), dtype=tf.float32, initializer=tf.keras.initializers.constant(0.0))\n",
    "    beta = tf.get_variable('beta', (1,1), dtype=tf.float32, initializer=tf.keras.initializers.orthogonal())\n",
    "\n",
    "y_pred = alpha + x @ beta\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    feed_dict = {x:x_data}\n",
    "    y_pred_run = sess.run(y_pred, feed_dict=feed_dict)\n",
    "    print(y_pred_run) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
